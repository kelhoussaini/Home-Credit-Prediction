{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the Modeling class in Home-Credit-Prediction/homecredit/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3218917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency # need this for chi-squared function\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbad704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = (os.path.dirname(os.getcwd()))\n",
    "sys.path.append(path_dir)\n",
    "    \n",
    "from homecredit.data import HomeCredit\n",
    "from homecredit.preparation import Preparation\n",
    "from homecredit.cleaner import Cleaning\n",
    "from homecredit.exploration import Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21234b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91206, 122)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.remove_missvalues() method\n",
    "# removes first some entries\n",
    "# then, Replaces the NaNs in numerical column by the mean of values\n",
    "# in numerical column respectively \n",
    "# for categorical variables, NaNs are replaced by ''\n",
    "df = Cleaning().remove_missvalues()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5ec9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "catcols = Cleaning().catcols # Preparation().get_catcols() # categorical columns\n",
    "numcols = Cleaning().numcols # Preparation().get_numcols() # numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c1a0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df.drop_duplicates(subset = df.columns)\n",
    "#data.shape\n",
    "#There are no duplicates values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a68d27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B : Here, we use OneHotEncoder, but we also can use \n",
    "#pandas.get_dummies. More, get_dummies easier than OneHotEncoder\n",
    "\n",
    "def encoding_categ_column(df, cols):\n",
    "    \n",
    "    for col_name in cols:\n",
    "    \n",
    "        L = list(df[col_name].unique())\n",
    "        if '' in L:\n",
    "            df[col_name].replace(\"\", \"NoValue\", inplace=True) #Replace NaN by \"NoCodeNature\"\n",
    "\n",
    "        ohe = OneHotEncoder(sparse = False) # Instanciate encoder\n",
    "        ohe.fit(df[[col_name]]) # Fit encoder  ---> OneHotEncoder(sparse=False)\n",
    "\n",
    "        col_encoded = ohe.transform(df[[col_name]]) # Encode\n",
    "\n",
    "        dicts_col = {}\n",
    "        keys = list(ohe.categories_[0])\n",
    "        values = col_encoded.T.astype(int)\n",
    "\n",
    "        for i,j in enumerate(keys):\n",
    "            dicts_col[j] = values[i,:]\n",
    "\n",
    "        result = pd.DataFrame.from_dict(dicts_col)\n",
    "\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        #Concat df and result dataframes\n",
    "        data_res = pd.concat([df, result], axis = 1)\n",
    "\n",
    "        if 'NoValue' in list(data_res.columns):\n",
    "            data_res = data_res.drop(columns= ['NoValue',col_name] )\n",
    "            df = data_res\n",
    "        else:\n",
    "            data_res = data_res.drop(columns= col_name)\n",
    "            df = data_res\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3356b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoding_categ_column(df = df,\n",
    "                                   cols = catcols)\n",
    "#encoded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "077d13cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.9194137855419925\n"
     ]
    }
   ],
   "source": [
    "# create X, y\n",
    "y = encoded_df.TARGET\n",
    "X = encoded_df.drop('TARGET', axis = 1)\n",
    "\n",
    "# Feature names\n",
    "#features = list(X.columns)\n",
    "\n",
    "# Split into Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# KNN model\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the Training data\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the Testing data\n",
    "score = neigh.score(X_test, y_test) \n",
    "print( \"score : \", score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc747407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.9214021659894115\n",
      "Accuracy: 0.9194137855419925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNN model\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the Training data\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "# cross validation \n",
    "# Test model performance \n",
    "score = cross_val_score(neigh, X_train, y_train, cv=5).mean() \n",
    "print(\"score : \", score)\n",
    "\n",
    "#  Predict on new data\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "# Test accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c379384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['roc_auc', 'accuracy']\n",
    "models = []\n",
    "results = []\n",
    "\n",
    "# Classifiers\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('DTC', DecisionTreeClassifier()))\n",
    "#models.append(('RF', RandomForestClassifier()))\n",
    "#models.append(('SVC', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "175e1d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LR  scoring: roc_auc  score 0.6130893675025983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LR  scoring: accuracy  score 0.9258818373955877\n",
      "Model:  KNN  scoring: roc_auc  score 0.5261843510796194\n",
      "Model:  KNN  scoring: accuracy  score 0.9214021659894115\n",
      "Model:  DTC  scoring: roc_auc  score 0.5319870075877831\n",
      "Model:  DTC  scoring: accuracy  score 0.8626965840476357\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    for s in scoring:\n",
    "        model.fit(X_train, y_train)\n",
    "        res = cross_val_score(model, X_train, y_train, cv=5, scoring=s).mean()\n",
    "        results.append(res)\n",
    "        print(\"Model: \", name, \" scoring:\", s, \" score\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a332c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenzaelhoussaini/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44da41c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9239090709743439\n"
     ]
    }
   ],
   "source": [
    "#  Predict on new data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Test accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f22960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "\n",
    "# create X, y\n",
    "y = encoded_df.TARGET\n",
    "X = encoded_df.drop('TARGET', axis = 1)\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler() # Instanciate StandarScaler\n",
    "scaler.fit(X)\n",
    "\n",
    "X_rescaled = scaler.transform(X)\n",
    "\n",
    "# Split into Train/Test\n",
    "X_train_sc, X_test_sc, y_train, y_test = train_test_split(X_rescaled, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "774e69ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LR  scoring: roc_auc  score 0.7400404423400226\n",
      "Model:  LR  scoring: accuracy  score 0.9253962741845608\n",
      "Model:  KNN  scoring: roc_auc  score 0.5481678467183916\n",
      "Model:  KNN  scoring: accuracy  score 0.9220443474965118\n",
      "Model:  DTC  scoring: roc_auc  score 0.5361585969728132\n",
      "Model:  DTC  scoring: accuracy  score 0.8607700002708627\n"
     ]
    }
   ],
   "source": [
    "scoring = ['roc_auc', 'accuracy']\n",
    "models = []\n",
    "results = []\n",
    "\n",
    "# Classifiers\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('DTC', DecisionTreeClassifier()))\n",
    "\n",
    "for name, model in models:\n",
    "    for s in scoring:\n",
    "        model.fit(X_train_sc, y_train)\n",
    "        res = cross_val_score(model, X_train_sc, y_train, cv=5, scoring=s).mean()\n",
    "        results.append(res)\n",
    "        print(\"Model: \", name, \" scoring:\", s, \" score\", res)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4daeda",
   "metadata": {},
   "source": [
    "**LogisticRegression model gives the best score**\n",
    "\n",
    "**Let's make predictions on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcfab5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.9253962741845608\n",
      "Accuracy: 0.9250420290914407\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "scoring = 'accuracy'\n",
    "\n",
    "model.fit(X_train_sc, y_train)\n",
    "res = cross_val_score(model, X_train_sc, y_train, cv=5, scoring=s).mean()\n",
    "print(\"score: \", res)  \n",
    "\n",
    "#  Predict on new data\n",
    "y_pred = model.predict(X_test_sc)\n",
    "\n",
    "# Test accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3892374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    \n",
    "    \"\"\" Initialize dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "    def execute_list(self, cols):\n",
    "        \n",
    "        for col_name in cols:\n",
    "    \n",
    "        L = list(df[col_name].unique())\n",
    "        if '' in L:\n",
    "            df[col_name].replace(\"\", \"NoValue\", inplace=True) #Replace NaN by \"NoCodeNature\"\n",
    "\n",
    "        ohe = OneHotEncoder(sparse = False) # Instanciate encoder\n",
    "        ohe.fit(df[[col_name]]) # Fit encoder  ---> OneHotEncoder(sparse=False)\n",
    "\n",
    "        col_encoded = ohe.transform(df[[col_name]]) # Encode\n",
    "\n",
    "        dicts_col = {}\n",
    "        keys = list(ohe.categories_[0])\n",
    "        values = col_encoded.T.astype(int)\n",
    "\n",
    "        for i,j in enumerate(keys):\n",
    "            dicts_col[j] = values[i,:]\n",
    "\n",
    "        result = pd.DataFrame.from_dict(dicts_col)\n",
    "\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        #Concat df and result dataframes\n",
    "        data_res = pd.concat([df, result], axis = 1)\n",
    "\n",
    "        if 'NoValue' in list(data_res.columns):\n",
    "            data_res = data_res.drop(columns= ['NoValue',col_name] )\n",
    "            df = data_res\n",
    "        else:\n",
    "            data_res = data_res.drop(columns= col_name)\n",
    "            df = data_res\n",
    "        \n",
    "        return df\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ecc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Modeling:\n",
    "    \n",
    "    def __init__(self):\n",
    "            \n",
    "        path_dir = (os.path.dirname(os.getcwd()))\n",
    "        sys.path.append(path_dir)\n",
    "        # Assign an attribute \".data\" to all new instances of Preparation\n",
    "        self.data = Cleaning().remove_entries() # good practice to be sure not to modify your `data` variable\n",
    "        self.catcols = Preparation().get_catcols()\n",
    "        self.numcols = Preparation().get_numcols()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
